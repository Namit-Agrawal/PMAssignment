% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Exercise},
  pdfauthor={Namit Agrawal, Timothy Cheng},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Exercise}
\author{Namit Agrawal, Timothy Cheng}
\date{08/16/20}

\begin{document}
\maketitle

\hypertarget{problem-1-visual-story-telling-green-buildings}{%
\subsection{\texorpdfstring{\textbf{Problem 1: Visual story telling:
green
buildings}}{Problem 1: Visual story telling: green buildings}}\label{problem-1-visual-story-telling-green-buildings}}

It does make sense to use the median rather than mean as the non-green
buildings have many outliers as suggested by the boxplot below

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-3-1} \end{center}

The stats guru is right about removing buildings with less than 10\%
occupancy as based on the summary below. Within the group of buildings
that have only 10\% occupancy, there is only one building with a green
rating. In addition, roughly half of the buildings have 3 stories and
very few buildings have a Class A designation. Hence we should remove
buildings with less than 10\% occupancy as it may distort the analysis.

\begin{verbatim}
##  CS_PropertyID        cluster            size           empl_gr      
##  Min.   :     57   Min.   :   8.0   Min.   :  1624   Min.   :-1.490  
##  1st Qu.: 239800   1st Qu.: 256.0   1st Qu.: 11661   1st Qu.: 1.740  
##  Median : 393481   Median : 371.0   Median : 40000   Median : 2.300  
##  Mean   :1084028   Mean   : 536.2   Mean   : 62209   Mean   : 3.884  
##  3rd Qu.: 819966   3rd Qu.:1002.0   3rd Qu.: 83770   3rd Qu.: 3.700  
##  Max.   :6008486   Max.   :1230.0   Max.   :427383   Max.   :67.780  
##                                                      NA's   :1       
##       Rent         leasing_rate      stories            age         renovated
##  Min.   :  7.00   Min.   :0.000   Min.   : 1.000   Min.   :  0.00   0:148    
##  1st Qu.: 16.23   1st Qu.:0.000   1st Qu.: 2.000   1st Qu.: 28.00   1: 67    
##  Median : 20.50   Median :0.000   Median : 3.000   Median : 57.00            
##  Mean   : 22.44   Mean   :1.280   Mean   : 4.819   Mean   : 54.42            
##  3rd Qu.: 27.00   3rd Qu.:0.375   3rd Qu.: 6.000   3rd Qu.: 85.00            
##  Max.   :111.11   Max.   :9.780   Max.   :19.000   Max.   :118.00            
##                                                                              
##  class_a    class_b            LEED     Energystar       green_rating
##  0:193   Min.   :0.0000   Min.   :0   Min.   :0.000000   0:214       
##  1: 22   1st Qu.:0.0000   1st Qu.:0   1st Qu.:0.000000   1:  1       
##          Median :0.0000   Median :0   Median :0.000000               
##          Mean   :0.4884   Mean   :0   Mean   :0.004651               
##          3rd Qu.:1.0000   3rd Qu.:0   3rd Qu.:0.000000               
##          Max.   :1.0000   Max.   :0   Max.   :1.000000               
##                                                                      
##       net           amenities  cd_total_07     hd_total07    total_dd_07  
##  Min.   :0.000000   0:189     Min.   : 130   Min.   :   0   Min.   :2103  
##  1st Qu.:0.000000   1: 26     1st Qu.: 684   1st Qu.:1419   1st Qu.:2869  
##  Median :0.000000             Median :1113   Median :2472   Median :4854  
##  Mean   :0.004651             Mean   :1676   Mean   :3141   Mean   :4816  
##  3rd Qu.:0.000000             3rd Qu.:2746   3rd Qu.:4916   3rd Qu.:6546  
##  Max.   :1.000000             Max.   :5240   Max.   :7200   Max.   :8244  
##                                                                           
##  Precipitation     Gas_Costs        Electricity_Costs  cluster_rent  
##  Min.   :10.46   Min.   :0.009487   Min.   :0.01782   Min.   :10.22  
##  1st Qu.:22.71   1st Qu.:0.010118   1st Qu.:0.02453   1st Qu.:18.05  
##  Median :25.55   Median :0.010296   Median :0.02887   Median :20.74  
##  Mean   :30.34   Mean   :0.011579   Mean   :0.03111   Mean   :23.99  
##  3rd Qu.:41.32   3rd Qu.:0.012117   3rd Qu.:0.03781   3rd Qu.:27.02  
##  Max.   :58.02   Max.   :0.028914   Max.   :0.06278   Max.   :65.94  
## 
\end{verbatim}

The median rent for green buildings and non-green buildings is correct
if buildings with more than 10\% occupancy rate are considered.

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 2
##   green_rating MedianRent
##   <fct>             <dbl>
## 1 0                  25.0
## 2 1                  27.6
\end{verbatim}

Assuming that the building is 250000 square feet, it seems that the
stats guru is correct about recuperating the costs in a little under 8
years.

\textbf{Confounding variables investigation}\\

\textbf{Renovated Buildings}\\
Based on the numerical summary analysis for buildings that are
renovated, it does not seem there is much confounding going on as the
median rents for non renovated and renovated buildings are similar
especially for green buildings

\begin{verbatim}
## `summarise()` regrouping output by 'renovated' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 4 x 3
## # Groups:   renovated [2]
##   renovated green_rating MedianRent
##   <fct>     <fct>             <dbl>
## 1 0         0                  27  
## 2 0         1                  27.6
## 3 1         0                  23.5
## 4 1         1                  27.0
\end{verbatim}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 2
##   renovated MedianRent
##   <fct>          <dbl>
## 1 0               27  
## 2 1               23.8
\end{verbatim}

\textbf{Number of Stories}\\
As suggested by the plot below, the median for stories is a valid
selection since there are some outliers. It looks there is not much
evidence of confounding for the number of stories in the building, even
though there is a slight increase in rent as the number of stories goes
up. The median for stories of green buildings only differs by 1, so
stories may not directly be affecting the rent.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-8-1} \end{center}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 2
##   green_rating MedianStories
##   <fct>                <dbl>
## 1 0                       10
## 2 1                       11
\end{verbatim}

\textbf{Age}\\

An initial analysis provides a stark contrast in age between green and
non-green buildings.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-10-1} \end{center}

However, it looks like there is no confounding for age, as there is no
correlation between the age of the building and the rent from the plot
below.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-11-1} \end{center}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 2
##   green_rating MedianAge
##   <fct>            <dbl>
## 1 0                   36
## 2 1                   22
\end{verbatim}

\textbf{Size}\\
It looks like size is definitely a confounding variable, as size is
correlated with rent from plot below and the median size for green
buildings is double that of non-green. Thus, there is a premium in rent
for larger sizes, as expected.

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 2
##   green_rating MedianSize
##   <fct>             <dbl>
## 1 0                123250
## 2 1                241199
\end{verbatim}

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-14-1} \end{center}

\textbf{Cluster Rent}\\
There does not seem to be confounding for cluster rent, as the median
for cluster rent is approximately the same between green and non-green
buildings. However, cluster rent is highly correlated with the rent of
the building.

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 2
##   green_rating MedianClusterRent
##   <fct>                    <dbl>
## 1 0                         25.2
## 2 1                         25.4
\end{verbatim}

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-16-1} \end{center}

\textbf{Class}\\
It looks like the Class designation of buildings is a confounding
variable, as Class A buildings have generally higher median rents - in
addition, having a green\_rating with the Class A designation drives
median rents even higher. Class A designated buildings seem to correlate
with overall rent as well.

\begin{verbatim}
## `summarise()` regrouping output by 'class_a' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 4 x 3
## # Groups:   class_a [2]
##   class_a green_rating MedianRent
##   <fct>   <fct>             <dbl>
## 1 0       0                  23.6
## 2 0       1                  25.7
## 3 1       0                  28.2
## 4 1       1                  28.4
\end{verbatim}

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-18-1} \end{center}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 2
##   class_a MedianRent
##   <fct>        <dbl>
## 1 0             23.9
## 2 1             28.2
\end{verbatim}

\textbf{Thoughts}\\
From the investigation above it seems like size and class are the only
confounding variables, as the green buildings tend to have larger spaces
and larger spaces have higher rent. However, the stats guru is only
taking into account the median rent of all the building with more than
10\% occupancy. If we apply another filter to include only 15 story
buildings, we see that the rent goes up drastically for green buildings
- all the way to 37 dollars. However, it may not be wise to use this
filter as there is only 10 green buildings that have 15 stories.

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 3
##   green_rating MedianRent   num
##   <fct>             <dbl> <int>
## 1 0                  24.4   156
## 2 1                  37.0    10
\end{verbatim}

In general, the guru is correct with his analysis, but the analysis is
performed on a dataset with a large range of different building
specifications. For example, the dataset only contains 10 green
buildings that have 15 stories. A larger sample size that adheres to the
developers desired specs would provide more valid results. \#\#
\textbf{Problem 2: Visual story telling: flights at ABIA}

\textbf{Most active airlines}\\

Here we analyze which airlines are most active throughout the year in
terms of the distance flown. As seen by the plot, it appears Southwest
(WN) and American Airlines(AA) are the most active in flying out of ABIA
and flying to ABIA.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-22-1} \end{center}

\textbf{Delays by Day of Week}\\

In the plot below, we analyze the departure and arrival delay for each
day of the week. There are more arrival delays than departure delays and
Friday is the worst day to travel to/from Austin.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-24-1} \end{center}

\textbf{Average Delays per Airline}\\

This plot analyzes the average departure and arrival delay for each
airline. It looks like Piedmont Airlines (US) arrives and departs early
on average as the delay time is negative.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-26-1} \end{center}

\textbf{Most common Delay types by Airline}\\

Here we analyze the proportions of delays by airlines via the type of
delay. It look like most airlines suffer from carrier and weather
delays.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-28-1} \end{center}

\textbf{Flights per hour of the Day}\\

The plot below analyzes what are most frequent departure and arrival
times. Passengers typically fly \emph{out} early in the morning and fly
\emph{in} late at night. Between noon and evening there is an even split
between passengers flying in and out.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-30-1} \end{center}

\textbf{Flights by City}\\

The plot below analyzes the top ten airports to which passengers fly to
and fly in from. Dallas and Houston are by far the most popular
destinations.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-32-1} \end{center}

\textbf{Average time spent flying by Airline}\\

The plot below analyzes the average time spent flying for each airline.
JetBlue (B6) flies for more than 3 hours on average.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-34-1} \end{center}

\textbf{Average deviation off of Schedule Departure Time}\\

The plot below analyzes on average how often an airline deviates from
its scheduled departure time. Most airlines leave between 0 to 10
minutes earlier than scheduled!

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-36-1} \end{center}

\hypertarget{problem-3-portfolio-modeling}{%
\subsection{\texorpdfstring{\textbf{Problem 3: Portfolio
modeling}}{Problem 3: Portfolio modeling}}\label{problem-3-portfolio-modeling}}

\textbf{Background}\\
For this problem, we are analyzing five different ETFs ranging from Gold
ETFs to Oil related ETFs.\\

We have chosen to go with 5 ETFs:\\
``GLD'' - The Fund seeks to achieve the performance of gold bullion less
the expenses of the Fund\\

``USO'' - The Fund seeks to reflect the performance of the spot price of
West Texas Intermediate light, sweet crude oil delivered to Cushing,
Oklahoma by investing in a mix of Oil Futures Contracts and Other Oil
Interests.\\

``VNQ'' - The Fund seeks to provide a high level of income and moderate
long-term capital appreciation by tracking the performance of a
benchmark index that measures the performance of publicly traded equity
REITs and other real estate-related investments.\\

``BNO'' - BNO tracks the Brent oil spot price using near-month ICE
futures contracts.\\

``SLV'' - The Fund seeks to reflect generally the performance of the
price of silver.\\

\textbf{Volatility}\\
Below are a few plots for the closing prices of ETF. The oil ETFs are
the most volatile of the five funds chosen.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-38-1} \end{center}

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-38-2} \end{center}

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-38-3} \end{center}

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-38-4} \end{center}

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-38-5} \end{center}

\textbf{Portfolios}\\
\textbf{Portfolio 1} : A portfolio of equal weights to all ETFs (i.e, 20
percent to all ETFs)
\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-40-1.pdf}

\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-41-1.pdf}

\begin{verbatim}
##       5% 
## 9673.958
\end{verbatim}

\begin{verbatim}
## [1] 99608.35
\end{verbatim}

The 5\% value at risk for this particular portfolio is roughly
\$9,674.\\

\textbf{Portfolio 2} : A portfolio that invests 96 percent of wealth
into gold and 1 percent into each of the remaining 4 ETFs.

\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-44-1.pdf}
\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-45-1.pdf}

\begin{verbatim}
##       5% 
## 5670.255
\end{verbatim}

\begin{verbatim}
## [1] 100490.9
\end{verbatim}

The 5\% value at risk for this particular portolio is roughly \$5,670.\\

\textbf{Portfolio 3} : A portfolio that invests 60 percent of wealth
into VNQ and 10 percent into each of the remaining 4 ETFs.

\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-48-1.pdf}
\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-49-1.pdf}

\begin{verbatim}
##       5% 
## 7694.568
\end{verbatim}

\begin{verbatim}
## [1] 100226.4
\end{verbatim}

The 5\% value at risk of this particular portfolio is roughly \$7,695.\\

\textbf{Report}\\
Based on our analysis, portfolio 2 performed the best. By investing 96\%
of our wealth into the gold ETF, we were able to achieve the highest
returns and the lowest VaR (value at risk) at 5\% between all
portfolios. This is an interesting result as diversification of the
portfolio hurt our investments which suggests that ETFs related to Oil
and Silver are significantly more volatile than Gold. This also suggests
that Gold is typically a safe investment to make.\\

\textbf{Problem 4: Market Segmentation}\\
From the dataset provided by the company ``NutrientH20'', we hope to
extract some vital market information regarding the types of followers
that ``NutrientH20'' has.

We first perform dimension reduction on the dataset to improve
computational ability. In addition, we can visualize the marginal
variance explained by adding another PC. Because the elbow is not clear
in this plot, we choose a value of 15 PCs to continue our analysis.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-52-1} \end{center}

Based on our understanding of the dataset, we can conclude which PCs are
associated with separating which types of followers. For example, in the
plot below, we can see that the third PC has weights that are strongly
positive for people that are interested in fitness, but not so much in
computers/gaming/politics.

\begin{center}\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-54-1} \end{center}

In contrast, our fourth PC (below) has strong negative weights for
health and fitness and seems to value online gaming and sports.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gamer <-}\StringTok{ }\KeywordTok{select}\NormalTok{(loadings,Category,PC4)}
\NormalTok{sorted <-}\StringTok{ }\KeywordTok{arrange}\NormalTok{(gamer,}\KeywordTok{desc}\NormalTok{(PC4))}
\KeywordTok{ggplot}\NormalTok{(sorted, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{reorder}\NormalTok{(Category,PC4), }\DataTypeTok{y=}\NormalTok{PC4)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{stat=}\StringTok{'identity'}\NormalTok{) }\OperatorTok{+}\StringTok{ }\KeywordTok{coord_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-55-1.pdf}
These two PCs, then would be good at separating and visualizing
different types of followers in a 2-Dimensional space.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scaled.pca <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(pca.social}\OperatorTok{$}\NormalTok{x[,}\DecValTok{1}\OperatorTok{:}\DecValTok{15}\NormalTok{])}
\NormalTok{scaled.points <-}\StringTok{ }\KeywordTok{select}\NormalTok{(scaled.pca,PC3,PC4)}
\KeywordTok{ggplot}\NormalTok{(scaled.points,}\KeywordTok{aes}\NormalTok{(PC3,PC4)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-56-1.pdf}
In order to determine clusters of followers in this space, we perform
kmeans clustering on our points in PC space. To determine the optimal
hyperparameter for clustering, we try several values of \emph{k} and
measure the best one using our within sum of squares as the metric.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scaled <-}\StringTok{ }\KeywordTok{as.data.frame}\NormalTok{(}\KeywordTok{scale}\NormalTok{(social[,}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{)],}\DataTypeTok{center =}\NormalTok{ T,}\DataTypeTok{scale =}\NormalTok{ T))}
\NormalTok{mu <-}\StringTok{ }\KeywordTok{attr}\NormalTok{(}\KeywordTok{scale}\NormalTok{(social[,}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{)]), }\StringTok{"scaled:center"}\NormalTok{)}
\NormalTok{sigma <-}\StringTok{ }\KeywordTok{attr}\NormalTok{(}\KeywordTok{scale}\NormalTok{(social[,}\OperatorTok{-}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{)]),}\StringTok{"scaled:scale"}\NormalTok{)}
\NormalTok{withinss =}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{(k }\ControlFlowTok{in} \DecValTok{2}\OperatorTok{:}\DecValTok{20}\NormalTok{)\{}
  \KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{  cluster_k =}\StringTok{ }\KeywordTok{kmeans}\NormalTok{(scaled, k, }\DataTypeTok{nstart=}\DecValTok{25}\NormalTok{)}
\NormalTok{  withinss=}\StringTok{ }\KeywordTok{c}\NormalTok{(withinss, cluster_k}\OperatorTok{$}\NormalTok{tot.withinss)}
\NormalTok{\}}
\KeywordTok{qplot}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{2}\OperatorTok{:}\DecValTok{20}\NormalTok{),withinss}
\NormalTok{      ,}\DataTypeTok{xlab =} \StringTok{"k"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{Exercise_Final_files/figure-latex/unnamed-chunk-57-1.pdf}
Based on the plot, we decided to choose \(k=7\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{cluster <-}\StringTok{ }\KeywordTok{kmeans}\NormalTok{(scaled, }\DecValTok{7}\NormalTok{, }\DataTypeTok{nstart=}\DecValTok{25}\NormalTok{)}
\CommentTok{#colors <- }
\end{Highlighting}
\end{Shaded}

\hypertarget{fit}{%
\section{fit}\label{fit}}

fit \textless- loadings.summary \%\textgreater\% select(Category,PC3)
\%\textgreater\% arrange(desc(PC3))

\hypertarget{college-gamer}{%
\section{college gamer}\label{college-gamer}}

game \textless- loadings.summary \%\textgreater\% select(Category,PC4)
\%\textgreater\% arrange(desc(PC4))

\hypertarget{college-gamer-1}{%
\section{college gamer}\label{college-gamer-1}}

loadings.summary \%\textgreater\% select(Category,PC5) \%\textgreater\%
arrange(desc(PC5))

\hypertarget{blogger}{%
\section{blogger}\label{blogger}}

loadings.summary \%\textgreater\% select(Category,PC6) \%\textgreater\%
arrange(desc(PC6))

\hypertarget{artisttravel-enthusiast}{%
\section{artist/travel enthusiast}\label{artisttravel-enthusiast}}

art \textless- loadings.summary \%\textgreater\% select(Category,PC7)
\%\textgreater\% arrange(desc(PC7))

\hypertarget{singles}{%
\section{singles}\label{singles}}

loadings.summary \%\textgreater\% select(Category,PC10) \%\textgreater\%
arrange(desc(PC10))

young \textless- loadings \%\textgreater\% select(Category,PC2)
\%\textgreater\% arrange(desc(PC2)) ggplot(young,
aes(x=reorder(Category,PC2), y=PC2)) + geom\_bar(stat=`identity') +
coord\_flip()

scaled \textless- as.data.frame(scale(social{[},-c(1){]},center =
T,scale = T)) mu \textless- attr(scale(social{[},-c(1){]}),
``scaled:center'') sigma \textless-
attr(scale(social{[},-c(1){]}),``scaled:scale'')

withinss = c() for(k in 2:20)\{ set.seed(1) cluster\_k = kmeans(scaled,
k, nstart=25) withinss= c(withinss,
cluster\_k\(tot.withinss) } plot(c(2:20), withinss) set.seed(1) cluster = kmeans(scaled, 7, nstart=25) cluster1=as.data.frame(cluster\)center{[}1,{]}\emph{sigma
+ mu)
cluster1\(category=row.names(cluster1) sort((cluster\)center{[}2,{]}}sigma
+ mu), decreasing=TRUE)
sort((cluster\(center[3,]*sigma + mu), decreasing=TRUE) sort((cluster\)center{[}4,{]}\emph{sigma
+ mu), decreasing=TRUE)
sort((cluster\(center[5,]*sigma + mu), decreasing=TRUE) sort((cluster\)center{[}6,{]}}sigma
+ mu), decreasing=TRUE)
sort((cluster\(center[7,]*sigma + mu), decreasing=TRUE) kmeansDF = as.data.frame(cbind(cluster\)center{[}1,{]}\emph{sigma
+ mu, cluster\(center[2,]*sigma + mu,  cluster\)center{[}3,{]}}sigma +
mu, cluster\(center[4,]*sigma + mu,  cluster\)center{[}5,{]}\emph{sigma
+ mu, cluster\(center[6,]*sigma + mu,  cluster\)center{[}7,{]}}sigma +
mu)) colnames(kmeansDF)\textless-
c(``Cluster\_1'',``Cluster\_2'',``Cluster\_3'', ``Cluster\_4'',
``Cluster\_5'', ``Cluster\_6'', ``Cluster\_7'') kmeansDF\$category
=row.names(kmeansDF) ggplot(kmeansDF,
aes(x=reorder(category,Cluster\_1), y=Cluster\_1)) +
geom\_bar(stat=`identity') + coord\_flip() ggplot(kmeansDF,
aes(x=reorder(category,Cluster\_2), y=Cluster\_2)) +
geom\_bar(stat=`identity') + coord\_flip() ggplot(kmeansDF,
aes(x=reorder(category,Cluster\_3), y=Cluster\_3)) +
geom\_bar(stat=`identity') + coord\_flip() ggplot(kmeansDF,
aes(x=reorder(category,Cluster\_4), y=Cluster\_4)) +
geom\_bar(stat=`identity') + coord\_flip() ggplot(kmeansDF,
aes(x=reorder(category,Cluster\_5), y=Cluster\_5)) +
geom\_bar(stat=`identity') + coord\_flip() ggplot(kmeansDF,
aes(x=reorder(category,Cluster\_6), y=Cluster\_6)) +
geom\_bar(stat=`identity') + coord\_flip() ggplot(kmeansDF,
aes(x=reorder(category,Cluster\_7), y=Cluster\_7)) +
geom\_bar(stat=`identity') + coord\_flip()

\end{document}
